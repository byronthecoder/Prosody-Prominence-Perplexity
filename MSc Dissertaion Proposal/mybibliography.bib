@article{Reference1,
	Abstract = {We have developed an enhanced Littrow configuration extended cavity diode laser (ECDL) that can be tuned without changing the direction of the output beam. The output of a conventional Littrow ECDL is reflected from a plane mirror fixed parallel to the tuning diffraction grating. Using a free-space Michelson wavemeter to measure the laser wavelength, we can tune the laser over a range greater than 10 nm without any alteration of alignment.},
	Author = {C. J. Hawthorn and K. P. Weber and R. E. Scholten},
	Journal = {Review of Scientific Instruments},
	Month = {December},
	Number = {12},
	Numpages = {3},
	Pages = {4477--4479},
	Title = {Littrow Configuration Tunable External Cavity Diode Laser with Fixed Direction Output Beam},
	Volume = {72},
	Url = {http://link.aip.org/link/?RSI/72/4477/1},
	Year = {2001}}

@article{Reference3,
	Abstract = {Operating a laser diode in an extended cavity which provides frequency-selective feedback is a very effective method of reducing the laser's linewidth and improving its tunability. We have developed an extremely simple laser of this type, built from inexpensive commercial components with only a few minor modifications. A 780~nm laser built to this design has an output power of 80~mW, a linewidth of 350~kHz, and it has been continuously locked to a Doppler-free rubidium transition for several days.},
	Author = {A. S. Arnold and J. S. Wilson and M. G. Boshier},
	Journal = {Review of Scientific Instruments},
	Month = {March},
	Number = {3},
	Numpages = {4},
	Pages = {1236--1239},
	Title = {A Simple Extended-Cavity Diode Laser},
	Volume = {69},
	Url = {http://link.aip.org/link/?RSI/69/1236/1},
	Year = {1998}}

@article{Reference2,
	Abstract = {We present a review of the use of diode lasers in atomic physics with an extensive list of references. We discuss the relevant characteristics of diode lasers and explain how to purchase and use them. We also review the various techniques that have been used to control and narrow the spectral outputs of diode lasers. Finally we present a number of examples illustrating the use of diode lasers in atomic physics experiments. Review of Scientific Instruments is copyrighted by The American Institute of Physics.},
	Author = {Carl E. Wieman and Leo Hollberg},
	Journal = {Review of Scientific Instruments},
	Keywords = {Diode Laser},
	Month = {January},
	Number = {1},
	Numpages = {20},
	Pages = {1--20},
	Title = {Using Diode Lasers for Atomic Physics},
	Volume = {62},
	Url = {http://link.aip.org/link/?RSI/62/1/1},
	Year = {1991}}

Automatically generated by Mendeley Desktop 1.19.5
Any changes to this file will be lost if it is regenerated by Mendeley.

BibTeX export options can be customized via Options -> BibTeX in Mendeley Desktop

@article{He2016,
	abstract = {Recent work has begun exploring neural acoustic word embeddings---fixed-dimensional vector representations of arbitrary-length speech segments corresponding to words. Such embeddings are applicable to speech retrieval and recognition tasks, where reasoning about whole words may make it possible to avoid ambiguous sub-word representations. The main idea is to map acoustic sequences to fixed-dimensional vectors such that examples of the same word are mapped to similar vectors, while different-word examples are mapped to very different vectors. In this work we take a multi-view approach to learning acoustic word embeddings, in which we jointly learn to embed acoustic sequences and their corresponding character sequences. We use deep bidirectional LSTM embedding models and multi-view contrastive losses. We study the effect of different loss variants, including fixed-margin and cost-sensitive losses. Our acoustic word embeddings improve over previous approaches for the task of word discrimination. We also present results on other tasks that are enabled by the multi-view approach, including cross-view word discrimination and word similarity.},
	archivePrefix = {arXiv},
	arxivId = {1611.04496},
	author = {He, Wanjia and Wang, Weiran and Livescu, Karen},
	eprint = {1611.04496},
	file = {:C$\backslash$:/Users/Optiplex 990/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/He, Wang, Livescu - Unknown - MULTI-VIEW RECURRENT NEURAL ACOUSTIC WORD EMBEDDINGS.pdf:pdf},
	title = {{Multi-view Recurrent Neural Acoustic Word Embeddings}},
	url = {https://github.com/opheadacheh/Multi-view-neural-acoustic-words-embeddings http://arxiv.org/abs/1611.04496},
	year = {2016}
}
@article{Zayats2019,
	abstract = {Disfluencies in spontaneous speech are known to be associated with prosodic disruptions. However, most algorithms for disfluency detection use only word transcripts. Integrating prosodic cues has proved difficult because of the many sources of variability affecting the acoustic correlates. This paper introduces a new approach to extracting acoustic-prosodic cues using text-based distributional prediction of acoustic cues to derive vector z-score features (innovations). We explore both early and late fusion techniques for integrating text and prosody, showing gains over a high-accuracy text-only model.},
	archivePrefix = {arXiv},
	arxivId = {1904.04388},
	author = {Zayats, Vicky and Ostendorf, Mari},
	eprint = {1904.04388},
	file = {:C$\backslash$:/Users/Optiplex 990/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Zayats, Ostendorf - Unknown - Giving Attention to the Unexpected Using Prosody Innovations in Disfluency Detection.pdf:pdf},
	title = {{Giving Attention to the Unexpected: Using Prosody Innovations in Disfluency Detection}},
	url = {https://arxiv.org/pdf/1904.04388.pdf http://arxiv.org/abs/1904.04388},
	year = {2019}
}
@phdthesis{Dabike2016,
	abstract = {Automatic Speech Recognition in music is a barely analysed problem which can be beneficial in creative and retail business applications. This project is aimed to experiment in a musical corpus with synthetic augmented training data and with DNN methodologies in order to determine if these approaches can improve the performance of recognizer. Previous researches used speaker to singer adaptation rather than training in a singing database. First, creating a novel corpus ACOMUS1 based in acoustic cover music and then several audio augmentations experiments will be conducted in order to try to reach a high performance and obtain information that would lead to further researches. The experiment results obtained a poor performance reaching a 86{\%} of WER using DNN sMBR nevertheless, ACOMUS1 corpus showed to have a high growth potential that would allow more researches on it.},
	author = {Dabike, Gerardo Roa},
	file = {:C$\backslash$:/Users/Optiplex 990/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Roa et al. - 2016 - Automatic Speech Recognition in Music.pdf:pdf},
	pages = {60},
	title = {{Automatic Speech Recognition in Music}},
	url = {https://www.dcs.shef.ac.uk/intranet/archive/campus/2015{\_}2016/projects/msc/acp15gr.pdf},
	year = {2016}
}
@article{Liu2011,
	author = {Liu, Fei and Liu, Feifan and Liu, Yang},
	file = {:C$\backslash$:/Users/Optiplex 990/Documents/CSSLP/A-Supervised-Framework-for-Keyword-Extraction-from-Meeting-Transcripts.pdf:pdf},
	journal = {IEEE Transactions on Audio, Speech, and Language Processing},
	keywords = {1,2,a variety,also be used for,both the transcripts and,built a,by extracting keywords from,for example,for spoken documents can,of spoken language processing,proposed a real time,speech queries,spoken document retrieval system,tasks},
	number = {3},
	pages = {538--548},
	title = {{A Supervised Framework for Keyword Extraction}},
	volume = {19},
	year = {2011}
}
@inproceedings{Xu2013,
	abstract = {This paper introduces ProsodyPro — A software tool for facilitating large-scale analysis of speech prosody, especially for experimental data. The program allows users to perform systematic analysis of large amounts of data and generates a rich set of output, including both continuous data like time- normalized F0 contours and F0 velocity profiles suitable for graphical analysis, and discrete measurements suitable for statistical analysis. It maximizes efficiency by automating tasks that do not require human judgment, and saving analysis output in formats that are ready for further graphical and statistical analysis.},
	author = {Xu, Yi},
	booktitle = {Proceedings of Tools and Resources for the Analysis of Speech Prosody (TRASP 2013)},
	file = {:C$\backslash$:/Users/Optiplex 990/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Xu - Unknown - ProsodyPro-A Tool for Large-scale Systematic Prosody Analysis.pdf:pdf},
	keywords = {F0 velocity,Index Terms: ProsodyPro,annotation,time-normalization},
	pages = {7--10},
	title = {{ProsodyPro-A Tool for Large-scale Systematic Prosody Analysis}},
	url = {http://discovery.ucl.ac.uk/1406070/1/Xu{\_}TRASP2013.pdf http://www.homepages.ucl.ac.uk/{~}uclyyix/yispapers/Xu{\_}TRASP2013.pdf},
	year = {2013}
}
@article{Chen2010,
	abstract = {Parallel als Druckausg. erschienen},
	author = {Chen, YN and Huang, Y},
	file = {:C$\backslash$:/Users/Optiplex 990/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/IEEE Signal Processing Society et al. - Unknown - IEEE Spoken Language Technology Workshop (SLT), 2010 12-15 Dec. 2010, Claremont Hotel.pdf:pdf},
	isbn = {9781424479030},
	journal = {Spoken Language {\ldots}},
	pages = {265--270},
	title = {{AUTOMATIC KEY TERM EXTRACTION FROM SPOKEN COURSE LECTURES USING BRANCHING ENTROPY AND PROSODIC / SEMANTIC FEATURES Graduate Institute of Computer Science and Information Engineering}},
	url = {http://ieeexplore.ieee.org/xpls/abs{\_}all.jsp?arnumber=5700862},
	year = {2010}
}
@book{Ladd2008,
	address = {Cambridge},
	author = {Ladd, D. Robert},
	doi = {10.1017/CBO9780511808814},
	isbn = {9780511808814},
	publisher = {Cambridge University Press},
	title = {{Intonational Phonology}},
	url = {http://ebooks.cambridge.org/ref/id/CBO9780511808814},
	year = {2008}
}
@article{Kafle2018,
	abstract = {Motivated by a project to create a system for people who are deaf or hard-of-hearing that would use automatic speech recognition (ASR) to produce real-time text captions of spoken English during in-person meetings with hearing individuals, we have augmented a transcript of the Switchboard conversational dialogue corpus with an overlay of word-importance annotations, with a numeric score for each word, to indicate its importance to the meaning of each dialogue turn. Further, we demonstrate the utility of this corpus by training an automatic word importance labeling model; our best performing model has an F-score of 0.60 in an ordinal 6-class word-importance classification task with an agreement (concordance correlation coefficient) of 0.839 with the human annotators (agreement score between annotators is 0.89). Finally, we discuss our intended future applications of this resource, particularly for the task of evaluating ASR performance, i.e. creating metrics that predict ASR-output caption text usability for DHH users better thanWord Error Rate (WER).},
	archivePrefix = {arXiv},
	arxivId = {1801.09746},
	author = {Kafle, Sushant and Huenerfauth, Matt},
	eprint = {1801.09746},
	file = {:C$\backslash$:/Users/Optiplex 990/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Kafle, Huenerfauth - Unknown - A Corpus for Modeling Word Importance in Spoken Dialogue Transcripts.pdf:pdf},
	keywords = {Speech Recognition Evaluation,Word Importance Annotation,Word Importance Prediction},
	title = {{A Corpus for Modeling Word Importance in Spoken Dialogue Transcripts}},
	url = {http://latlab.ist.rit.edu/lrec2018 http://arxiv.org/abs/1801.09746},
	year = {2018}
}
@article{Atterer2000,
	abstract = {This thesis presents a model that assigns prosodic structure to unrestricted text. The model is linguistically motivated. For the implementation an XML-pipeline is used as a data-architecture. The output can be processed by a text-to-speech synthesiser for determining the locations of phrase breaks. The model's performance is evaluated in various ways. It outper-forms another rule-based approach, and achieves either comparable results as a statistical model or comes close to those results, while being psychologically more plausible.},
	author = {Atterer, Michaela},
	file = {:C$\backslash$:/Users/Optiplex 990/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Atterer - Unknown - Assigning Prosodic Structure for Speech Synthesis via Syntax-Prosody Mapping.pdf:pdf},
	title = {{Assigning Prosodic Structure for Speech Synthesis via Syntax-Prosody Mapping}},
	url = {https://www.inf.ed.ac.uk/publications/thesis/online/IM000107.pdf},
	year = {2000}
}
@inproceedings{Silverman1992,
	abstract = {An understanding of prosody is critical in basic research in speech and natural language processing, and in the technology for building high quality speech synthesis and spoken language understanding systems. Sufficient understanding and development of computational models require large amounts of prosodically transcribed speech. Unfortunately there is no single standard for prosodic transcription that is analogous to IPA for phonetic segments. To meet this need, a group of researchers with expertise in a variety of approaches to prosodic analysis and speech technology have developed TOBI: an agreed transcription system which builds on much recent progress in prosodic modelling. In a study with twenty transcribers with varied experience using this system and a total of 20,000 decisions, high inter-transcriber reliability was achieved. We report this and other evaluations of TOBI which document the consistency with which it can be used. We propose this system as a standard for prosodic transcription of large speech corpora.},
	author = {Silverman, Kim and Beckman, Mary and Pitrelli, John and Ostendorf, Mari and Wightman, Colin and Price, Patti and Pierrehumbert, Janet and Hirschberg, Julia},
	booktitle = {2nd International Conference on Spoken Language Processing (ICSLP 92)},
	file = {:C$\backslash$:/Users/Optiplex 990/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Unknown - Unknown - full-text(3).pdf:pdf},
	pages = {867--870},
	title = {{TOBI: A Standard for Labeling English Prosody}},
	year = {1992}
}
@article{Mikolov2013,
	abstract = {We propose two novel model architectures for computing continuous vector representations of words from very large data sets. The quality of these representations is measured in a word similarity task, and the results are compared to the previously best performing techniques based on different types of neural networks. We observe large improvements in accuracy at much lower computational cost, i.e. it takes less than a day to learn high quality word vectors from a 1.6 billion words data set. Furthermore, we show that these vectors provide state-of-the-art performance on our test set for measuring syntactic and semantic word similarities.},
	archivePrefix = {arXiv},
	arxivId = {1301.3781},
	author = {Mikolov, Tomas and Chen, Kai and Corrado, Greg and Dean, Jeffrey},
	eprint = {1301.3781},
	file = {:C$\backslash$:/Users/Optiplex 990/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Mikolov et al. - Unknown - Efficient Estimation of Word Representations in Vector Space.pdf:pdf},
	title = {{Efficient Estimation of Word Representations in Vector Space}},
	url = {http://ronan.collobert.com/senna/ http://arxiv.org/abs/1301.3781},
	year = {2013}
}
@article{Gorisch2012,
	author = {Gorisch, Jan P F M},
	file = {:C$\backslash$:/Users/Optiplex 990/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Gorisch - Unknown - Matching across Turns in Talk-in-Interaction The Role of Prosody and Gesture.pdf:pdf},
	title = {{Jan P. F. M. Gorisch Matching across Turns in Talk-in-Interaction: The Role of Prosody and Gesture}},
	url = {http://etheses.whiterose.ac.uk/3812/1/2013{\_}03{\_}22{\_}E-Thesis{\_}Gorisch.pdf},
	year = {2012}
}
@phdthesis{Grefenstette2010,
	author = {Grefenstette, Edward and Pulman, Stephen},
	file = {:C$\backslash$:/Users/Optiplex 990/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Grefenstette, Pulman - 2010 - MSc Computer Science Dissertation Analysing Document Similarity Measures.pdf:pdf},
	title = {{MSc Computer Science Dissertation Analysing Document Similarity Measures}},
	url = {http://www.cs.ox.ac.uk/people/edward.grefenstette/MScThesis.pdf},
	year = {2010}
}
@article{DeJong2009,
	abstract = {In this article, we describe a method for automatically detecting syllable nuclei in order to measure speech rate without the need for a transcription. A script written in the software program Praat (Boersma {\&} Weenink, 2007) detects syllables in running speech. Peaks in intensity (dB) that are preceded and followed by dips in intensity are considered to be potential syllable nuclei. The script subsequently discards peaks that are not voiced. Testing the resulting syllable counts of this script on two corpora of spoken Dutch, we obtained high correlations between speech rate calculated from human syllable counts and speech rate calculated from automatically determined syllable counts. We conclude that a syllable count measured in this automatic fashion suffices to reliably assess and compare speech rates between participants and tasks.},
	author = {de Jong, Nivja H. and Wempe, Ton},
	doi = {10.3758/BRM.41.2.385},
	file = {:C$\backslash$:/Users/Optiplex 990/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/de Jong, Wempe - 2009 - Praat script to detect syllable nuclei and measure speech rate automatically.pdf:pdf},
	issn = {1554351X},
	journal = {Behavior Research Methods},
	month = {may},
	number = {2},
	pages = {385--390},
	title = {{Praat script to detect syllable nuclei and measure speech rate automatically}},
	volume = {41},
	year = {2009}
}
@techreport{Gibbon2019,
	abstract = {There are many research tools which are also used for teaching the acoustic phonetics of speech rhythm and speech melody. But they were not purpose-designed for teaching-learning situations, and some have a steep learning curve. CRAFT (Creation and Recovery of Amplitude and Frequency Tracks) is custom-designed as a novel flexible online tool for visualisation and critical comparison of functions and transforms, with implementations of the Reaper, RAPT, PyRapt, YAAPT, YIN and PySWIPE F0 estimators, three Praat configurations, and two purpose-built estimators, PyAMDF, S0FT. Visualisations of amplitude and frequency envelope spectra, spectral edge detection of rhythm zones, and a parametrised spectrogram are included. A selection of audio clips from tone and intonation languages is provided for demonstration purposes. The main advantages of online tools are consistency (users have the same version and the same data selection), interoperability over different platforms, and ease of maintenance. The code is available on GitHub.},
	author = {Gibbon, Dafydd},
	file = {:C$\backslash$:/Users/Optiplex 990/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Gibbon - Unknown - CRAFT A Multifunction Online Platform for Speech Prosody Visualisation.pdf:pdf},
	keywords = {f0 estimation,intonation,pitch extraction,prosody visualisation,rhythm zone,tone},
	title = {{CRAFT: A Multifunction Online Platform for Speech Prosody Visualisation}},
	url = {http://wwwhomes.uni-bielefeld.de/gibbon/CRAFT/},
	year = {2019}
}
@inproceedings{Hong2015,
	abstract = {We introduce a supervised model for predicting word importance that incorporates a rich set of features. Our model is superior to prior approaches for identifying words used in human summaries. Moreover we show that an extractive summarizer using these estimates of word importance is comparable in automatic evaluation with the state-of-the-Art. {\textcopyright} 2014 Association for Computational Linguistics.},
	author = {Hong, Kai and Nenkova, Ani},
	doi = {10.3115/v1/e14-1075},
	file = {:C$\backslash$:/Users/Optiplex 990/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Hong, Nenkova - Unknown - Improving the Estimation of Word Importance for News Multi-Document Summarization.pdf:pdf},
	pages = {712--721},
	title = {{Improving the Estimation of Word Importance for News Multi-Document Summarization}},
	url = {https://www.aclweb.org/anthology/E14-1075},
	year = {2015}
}
@article{Rayner2011,
	abstract = {Eye movements were monitored as subjects read sentences containing high- or low-predictable target words. The extent to which target words were predictable from prior context was varied: Half of the target words were predictable, and the other half were unpredictable. In addition, the length of the target word varied: The target words were short (4–6 letters), medium (7–9 letters), or long (10–12 letters). Length and predictability both yielded strong effects on the probability of skipping the target words and on the amount of time readers fixated the target words (when they were not skipped). However, there was no interaction in any of the measures examined for either skipping or fixation time. The results demonstrate that word predictability (due to contextual constraint) and word length have strong and independent influences on word skipping and fixation durations. Furthermore, because the long words extended beyond the word identification span, the data indicate that skipping can occur on the basis of partial information in relation to word identity. (PsycINFO Database Record (c) 2012 APA, all rights reserved) (journal abstract)},
	author = {Rayner, Keith and Slattery, Timothy J and Drieghe, Denis and Liversedge, Simon P},
	doi = {10.1037/a0020990},
	file = {:C$\backslash$:/Users/Optiplex 990/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Rayner et al. - 2011 - Eye movements and word skipping during reading Effects of word length and predictability NIH Public Access {\$}water.pdf:pdf},
	issn = {00961523},
	journal = {Journal of Experimental Psychology: Human Perception and Performance},
	keywords = {Eye movements,Reading,Word length,Word predictability},
	number = {2},
	pages = {514--528},
	title = {{Eye Movements and Word Skipping During Reading: Effects of Word Length and Predictability}},
	url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3543826/pdf/nihms430116.pdf},
	volume = {37},
	year = {2011}
}
@phdthesis{Schlunz2014,
	author = {Schl{\"{u}}nz, G I and Barnard, E},
	file = {:C$\backslash$:/Users/Optiplex 990/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Schl{\"{u}}nz, Barnard - 2014 - Advanced natural language processing for improved prosody in text-to-speech synthesis.pdf:pdf},
	keywords = {OCC model,affect,discourse,emotif,information structure,natural language processing,prosody,text-to-speech synthesis},
	title = {{Advanced natural language processing for improved prosody in text-to-speech synthesis}},
	url = {https://pdfs.semanticscholar.org/65e3/3098a8b011d90e429ad603b97c928f0ecf05.pdf http://dspace.nwu.ac.za/bitstream/handle/10394/10634/Schl{\"{u}}nz{\_}GI.pdf?sequence=1},
	year = {2014}
}
@techreport{Watton,
	abstract = {Introduction and Aims The aim of this project background report is to help you prepare for the summer MSc project. The main component of the report is an extensive literature survey (or similar technology/mathematical survey for certain types of project). In addition, the report should contain a clear presentation of what the project is aiming to achieve, and a description of the work done so far. It should also include a detailed project plan, including consideration of how risk will be managed during the project and consideration of legal/ethical issues.},
	author = {Watton, Paul},
	file = {:C$\backslash$:/Users/Optiplex 990/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Watton - Unknown - COM6905 Research Methods and Professional Issues Project Background Report (worth 80{\%} of module assessment).pdf:pdf},
	title = {{COM6905 Research Methods and Professional Issues Project Background Report (worth 80{\%} of module assessment)}},
	url = {https://learn-eu-central-1-prod-fleet01-xythos.s3-eu-central-1.amazonaws.com/5c8f80ee07c44/3121205?response-content-disposition=inline{\%}3B filename{\%}2A{\%}3DUTF-8{\%}27{\%}27COM6905{\_}Background{\_}Report{\_}Instructions.pdf{\&}response-content-type=application{\%}2Fpdf{\&}X-Amz-Alg}
}
@incollection{HaCohen-Kerner2010,
	abstract = {Many academic journals and conferences require that each article include a list of keyphrases. These keyphrases should provide general information about the contents and the topics of the article. Keyphrases may save precious time for tasks such as filtering, summarization, and categorization. In this paper, we investigate automatic extraction and learning of keyphrases from scientific articles written in English. Firstly, we introduce various baseline extraction methods. Some of them, formalized by us, are very successful for academic papers. Then, we integrate these methods using different machine learning methods. The best results have been achieved by J48, an improved variant of C4.5. These results are significantly better than those achieved by previous extraction systems, regarded as the state of the art.},
	author = {HaCohen-Kerner, Yaakov and Gross, Zuriel and Masa, Asaf},
	doi = {10.1007/978-3-540-30586-6_74},
	file = {:C$\backslash$:/Users/Optiplex 990/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Hacohen-Kerner, Gross, Masa - Unknown - Automatic Extraction and Learning of Keyphrases from Scientific Articles.pdf:pdf},
	pages = {657--669},
	title = {{Automatic Extraction and Learning of Keyphrases from Scientific Articles}},
	url = {http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.723.7243{\&}rep=rep1{\&}type=pdf},
	year = {2010}
}
@article{Pierrehumbert2015,
	abstract = {Recent investigations of the contribution that intonation makes to overall utterance and discourse interpretation promise new sources of information for the investigation of long-time concerns in natural-language processing. In Hirschberg and Pierrehumbert 1986 we proposed that intonational features such as phrasing, accmt pUuttTWIt, pilch rangt, and huIe represent important sources of information about the attmh0ru3l and the rntmt10rIJAl structures of discourse. I In this paper we examine the particular contribution of choice of tune, or int0ru3h0ru3l cantour, to discourse interpretation. In particular, we propose that a speaker (5) chooses a particular tune to convey a particular relationship between an utterance, currently perceived beliefs of a hearer or hearers (H), and anticipated contributions of subsequent utterances. We claim that these relationships are compositional-composed from the pitch aumts, phrase QCcmts, and bowndary tones that make up tunes. We further propose that the different aspects of tune meaning can be associated with different phonological domains. We assume the intorIJA-tional phrase as our primary unit of meaning analysis. In the following discussion we put forward a first approximation of a compositional theory of tune interpretation. together with the phonologi-cal assumptions on which it is based and the evidence from which we have drawn our proposals. We assume Pierrehumbert's Wierrehumbert 198{\{}); Beckman and Pierrehurnbert 1986a) theory of intonational description. which we describe in sections 2-3. In section 4 we present our general approach to intonational meaning. In sections 5-7 we present the data upon which we base this account. In section 8 we explore avenues of further development for the theory and discuss implications for the study of discourse. 2 Dimmslcn5 of IntOf1lltianai Variation 2.1 Prrlimiruzries In describing intonation patterns, we distinguish str{\~{}}, twu, phrasing, and PItch rar1Kt. 5t-r{\~{}} refers to the rhythmic pattern or relative prominence of}},
	author = {Pierrehumbert, Janet and Hirschberg, Julia},
	file = {:C$\backslash$:/Users/Optiplex 990/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/lqQO, Pierrehumberl, Hirschberg - Unknown - {\~{}}{\~{}}{\~{}}{\~{}} {\~{}}J.{\~{}}{\~{}}M{\~{}}{\~{}} P{\~{}} The Meaning of Intonational Contours in the Interpretation of Discourse.pdf:pdf},
	title = {{Chapter 14 The Meaning of Intonational Contours in the Interpretation of Discourse}},
	year = {2015}
}
@article{Y.MATSUO2004,
	abstract = {We present a new keyword extraction algorithm that applies to a single document without using a corpus. Frequent terms are extracted first, then a set of co-occurrences between each term and the frequent terms, i.e., occurrences in the same sentences, is generated. Co-occurrence distribution shows importance of a term in the document as follows. If the probability distribution of co-occurrence between term a and the frequent terms is biased to a particular subset of frequent terms, then term a is likely to be a keyword. The degree of bias of a distribution is measured by the $\chi$2-measure. Our algorithm shows comparable performance to tfidf without using a corpus.},
	author = {{Y. MATSUO}, M ISHIZUKA},
	doi = {10.1142/S0218213004001466},
	file = {:C$\backslash$:/Users/Optiplex 990/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Matsuo, Ishizuka - Unknown - Keyword Extraction from a Single Document using Word Co-occurrence Statistical Information.pdf:pdf},
	isbn = {1577351770},
	issn = {0218-2130},
	journal = {International Journal on Artificial Intelligence tools},
	keywords = {document using,extraction from a single,word co-occurrence statistical information},
	number = {1},
	pages = {157--169},
	title = {{KEYWORD EXTRACTION FROM A SINGLE DOCUMENT USING WORD CO-A20OCCURRENCE STATISTICAL Information}},
	url = {www.aaai.org},
	volume = {13},
	year = {2004}
}
@article{Murdoch2018,
	abstract = {The driving force behind the recent success of LSTMs has been their ability to learn complex and non-linear relationships. Consequently, our inability to describe these relationships has led to LSTMs being characterized as black boxes. To this end, we introduce contextual decomposition (CD), an interpretation algorithm for analysing individual predictions made by standard LSTMs, without any changes to the underlying model. By decomposing the output of a LSTM, CD captures the contributions of combinations of words or variables to the final prediction of an LSTM. On the task of sentiment analysis with the Yelp and SST data sets, we show that CD is able to reliably identify words and phrases of contrasting sentiment, and how they are combined to yield the LSTM's final prediction. Using the phrase-level labels in SST, we also demonstrate that CD is able to successfully extract positive and negative negations from an LSTM, something which has not previously been done.},
	archivePrefix = {arXiv},
	arxivId = {1801.05453},
	author = {Murdoch, W James and Liu, Peter J. and Yu, Bin},
	eprint = {1801.05453},
	file = {:C$\backslash$:/Users/Optiplex 990/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Murdoch et al. - Unknown - BEYOND WORD IMPORTANCE CONTEXTUAL DE-COMPOSITION TO EXTRACT INTERACTIONS FROM LSTMS.pdf:pdf},
	title = {{Beyond Word Importance: Contextual Decomposition to Extract Interactions from LSTMs}},
	url = {https://arxiv.org/pdf/1801.05453.pdf http://arxiv.org/abs/1801.05453},
	year = {2018}
}
@article{Beckman2010,
	abstract = {This chapter presents an overview of the original ToBI system. It reviews the design of the original ToBI system and its foundations in basic and applied research. It describes the inter-disciplinary community of users and uses for which the system was intended, and it outlines how the consensus model of American English intonation and inter-word juncture was achieved by finding points of useful intersection among the research interests and knowledge embodied in this community. It thus identifies the practical principles for designing prosodic annotation conventions that emerged in the course of developing, testing, and using this particular system. The chapter also describes how the original ToBI conventions have been evolved to be the general annotation conventions for several other English varieties and for a number of other languages.},
	author = {Beckman, Mary E. and Hirschberg, Julia and Shattuck-Hufnagel, Stefanie},
	doi = {10.1093/acprof:oso/9780199249633.003.0002},
	file = {:C$\backslash$:/Users/Optiplex 990/Documents/CSSLP/BeckHirschShattuckToBI.pdf:pdf},
	isbn = {9780191719349},
	journal = {Prosodic Typology: The Phonology of Intonation and Phrasing},
	keywords = {Allophonic transcription,Extensions of tobi,Intsint,Ivie,Original tobi system,Phonetic representation,Phonological transcription,ToBI},
	pages = {1--37},
	title = {{The Original ToBi System and the Evolution of the ToBi Framework}},
	year = {2010}
}
@inproceedings{Godfrey1992,
	abstract = {SWITCHBOARD is a large multispeaker corpus of conversational speech and text which should be of interest to researchers in speaker authentication and large vocabulary speech recognition. About 2500 conversations by 500 speakers from around the US were collected automatically over T1 lines at Texas Instruments. Designed for training and testing of a variety of speech processing algorithms, especially in speaker verification, it has over an 1 h of speech from each of 50 speakers, and several minutes each from hundreds of others. A time-aligned word for word transcription accompanies each recording},
	author = {Godfrey, John J. and Holliman, Edward C. and McDaniel, Jane},
	booktitle = {ICASSP, IEEE International Conference on Acoustics, Speech and Signal Processing - Proceedings},
	doi = {10.1109/ICASSP.1992.225858},
	isbn = {0780305329},
	issn = {15206149},
	pages = {517--520},
	publisher = {IEEE},
	title = {{SWITCHBOARD: Telephone speech corpus for research and development}},
	url = {http://ieeexplore.ieee.org/document/225858/},
	volume = {1},
	year = {1992}
}
@article{Tamburini2003,
	abstract = {This paper presents work in progress on the automatic detection of prosodic prominence in continuous speech. Prosodic prominence involves two different phonetic features: pitch accents, connected with fundamental frequency (F0) movements and syllable overall energy, and stress, which exhibits a strong correlation with syllable nuclei duration and mid-to-high-frequency emphasis. By measuring these acoustic parameters it is possible to build an automatic system capable of correctly identifying prominent syllables with an agreement, with human-tagged data, comparable with the inter-human agreement reported in the literature. This system does not require any training phase, additional information or annotation, it is not tailored to a specific set of data and can be easily adapted to different languages.},
	author = {Tamburini, Fabio},
	file = {:C$\backslash$:/Users/Optiplex 990/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Tamburini - Unknown - Automatic Prosodic Prominence Detection in Speech using Acoustic Features an Unsupervised System.pdf:pdf},
	journal = {European Conference on Speech Communication and Technology - EUROSPEECH},
	keywords = {Prominence},
	pages = {129--132},
	title = {{Automatic Prosodic Prominence Detection in Speech using Acoustic Features: an Unsupervised System}},
	url = {https://www.isca-speech.org/archive/archive{\_}papers/eurospeech{\_}2003/e03{\_}0129.pdf},
	year = {2003}
}
@misc{PaulBoersma&DavidWeenink2018,
	author = {{Paul Boersma {\&} David Weenink}},
	doi = {10.1097/AUD.0b013e31821473f7},
	issn = {0196-0202},
	title = {{Praat: Doing Phonetics by Computer}},
	url = {http://www.fon.hum.uva.nl/praat/ https://insights.ovid.com/crossref?an=00003446-201103000-00012},
	urldate = {2019-05-11},
	year = {2018}
}
@inproceedings{Pitrelli1994,
	abstract = {A diverse group of speech scientists and engineers has developed the ToBI (TOnes and Break Indices) prosodic transcription system and materials to teach it to transcribers. ToBI consists of parallel tiers reflecting the multiple components of prosody, the most important being a tone tier, for intonational analysis, and a break index tier, for indicating strength of coherence or disjuncture between adjacent words. To assess the system, we measured inter-transcriber agreement on utterances representative of the varied types of speech important to researchers, employing a diverse set of transcribers ranging from experts to newly-trained users. Consistency was measured in terms of number of transcriber pairs agreeing on the labeling of each particular word, a stringent metric. Using the metric, we observe 88{\%} agreement on the presence or absence of a particular category of tonal element, and 81{\%} agreement on the exact label for a tonal category. For break indices, agreement to within one level occurs 92{\%} of the time. We conclude that the ToBI standard and its training materials have been refined to the point that they can be used fruitfully for large-scale annotation of prosodic phenomena in speech databases.},
	author = {Pitrelli, John F. and Beckman, Mary E. and Hirschberg, Julia},
	booktitle = {3rd International Conference on Spoken Language Processing},
	file = {:C$\backslash$:/Users/Optiplex 990/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Unknown - Unknown - full-text(5).pdf:pdf},
	number = {September},
	pages = {123--126},
	title = {{Evaluation of Prosodic Transcription Labeling Reliability in the {\{}ToBI{\}} Framework}},
	year = {1994}
}
@article{Frazier2006,
	abstract = {Words, like musical notes, are grouped together into phrases by their rhythmic and durational properties as well as their tonal pitch. This 'prosodic phrasing' affects the understanding of sentences. Many processing studies of prosody have investigated sentences with a single, grammatically required prosodic boundary, which might be interpreted strictly locally, as a signal to end the current syntactic unit. Recent results suggest, however, that the global pattern of prosodic phrasing is what matters in sentence comprehension, not just the occurrence or size of a single local boundary. In this article we claim that the impact of prosodic boundaries depends on the other prosodic choices a speaker has made. We speculate that prosody serves to hold distinct linguistic representations together in memory. {\textcopyright} 2006 Elsevier Ltd. All rights reserved.},
	author = {Frazier, Lyn and Carlson, Katy and Clifton, Charles},
	doi = {10.1016/j.tics.2006.04.002},
	file = {:C$\backslash$:/Users/Optiplex 990/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Frazier, Carlson, Clifton - Unknown - Prosodic phrasing is central to language comprehension.pdf:pdf},
	issn = {13646613},
	journal = {Trends in Cognitive Sciences},
	number = {6},
	pages = {244--249},
	title = {{Prosodic phrasing is central to language comprehension}},
	url = {www.sciencedirect.com},
	volume = {10},
	year = {2006}
}
@inproceedings{Chung2018,
	abstract = {In this paper, we propose a novel deep neural network architecture, Speech2Vec, for learning fixed-length vector representations of audio segments excised from a speech corpus, where the vectors contain semantic information pertaining to the underlying spoken words, and are close to other vectors in the embedding space if their corresponding underlying spoken words are semantically similar. The proposed model can be viewed as a speech version of Word2Vec. Its design is based on a RNN Encoder-Decoder framework, and borrows the methodology of skipgrams or continuous bag-of-words for training. Learning word embeddings directly from speech enables Speech2Vec to make use of the semantic information carried by speech that does not exist in plain text. The learned word embeddings are evaluated and analyzed on 13 widely used word similarity benchmarks, and outperform word embeddings learned by Word2Vec from the transcriptions.},
	archivePrefix = {arXiv},
	arxivId = {1803.08976v2},
	author = {Chung, Yu An and Glass, James},
	booktitle = {Proceedings of the Annual Conference of the International Speech Communication Association, INTERSPEECH},
	doi = {10.21437/Interspeech.2018-2341},
	eprint = {1803.08976v2},
	file = {:C$\backslash$:/Users/Optiplex 990/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Chung, Glass - Unknown - Speech2Vec A Sequence-to-Sequence Framework for Learning Word Embeddings from Speech.pdf:pdf},
	issn = {19909772},
	keywords = {Bag-of-words,Recurrent neural networks,Sequence-to-sequence learning,Skipgrams,Word embeddings},
	pages = {811--815},
	title = {{Speech2Vec: A sequence-to-sequence framework for learning word embeddings from speech}},
	url = {https://arxiv.org/pdf/1803.08976.pdf},
	volume = {2018-Septe},
	year = {2018}
}
@article{Cutler1995,
	author = {Cutler, Anne and Dahan, D and van Donselaar, W},
	file = {:C$\backslash$:/Users/Optiplex 990/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Unknown - Unknown - full-text.pdf:pdf},
	journal = {Language and Speech},
	number = {2},
	pages = {141--201},
	title = {{Prosody in the Comprehension of spoken language}},
	volume = {40},
	year = {1995}
}
@article{I.Sheeba2012,
	abstract = {Keywords play a vital role in extracting the correct information as per user requirements. Keywords are like index terms that contain the most important information about the content of the document. Keyword Extraction is the task of identifying a keyword or keyphrase from a document that can help users easily to understand the documents . Meeting transcripts is significantly different from document or other speech domains. This paper aims to extract keywords and keyphrases from meeting transcripts and also to add some additional features for improving the keyword and keyphrase extraction method . Here, this method is performed by both human transcripts and ASR transcripts and the keywords are extracted through MaxEnt and SVM classifier and Extraction of bigram and trigram keywords retrieval using N-gram based approach efficiently and also to identify the low frequency keywords using LDA (Latent Dirichlet Approach).Finally, the quality of the Extracted keywords is improved using pattern features through sequential pattern mining.},
	author = {I.Sheeba, J. and Vivekanandan, K},
	doi = {10.5120/8260-1800},
	file = {:C$\backslash$:/Users/Optiplex 990/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Sheeba, Vivekanandan - 2012 - Improved Keyword and Keyphrase Extraction from Meeting Transcripts.pdf:pdf},
	journal = {International Journal of Computer Applications},
	keywords = {General Terms Data Mining,Keyphrase,Keyword Extraction Keywords Keywords,LDA,MaxEnt,Meeting Transcripts,SVM,Text Mining},
	number = {13},
	pages = {11--15},
	title = {{Improved Keyword and Keyphrase Extraction from Meeting Transcripts}},
	url = {https://pdfs.semanticscholar.org/eb0f/2ea57c35385f661b5119493e00dad4b6189c.pdf},
	volume = {52},
	year = {2012}
}
@incollection{Pierrehumbert1990,
	abstract = {Intro: Recent investigations of the contribution that intonation makes to overall utternace and discours interpreation promis new sources of information for the investigation of long-time concerns in natural language processing. In Hirschberg and Pierrehumbert 1986 we proposed that intonational featurees such as phrasing, accent placement, pitch range, and tune represent important sources of information about the attentional and the intentional structures of discourse. In this paper we examine the particualar contirbution of choice of tune, or intonational contour, to discourse interpretation. In particular, we propose that a speaker (S) chooses a particular tune to convey a particular relationship between an utterance, currently perceived beliefs of a hearer or hearers (H), and anticipated contributions of subsequent utterances. We claim that these relationships are compositional - composed from the pitch accents, phrase accents, and boundary tones that make up tunes. We further propose that the different aspects of tune meaning can be associated with different phonological domains. We assume the intonational phrase as our primary unity of meaning analysis. Discussion: In this paper we have presented the beginning of a compositional theory of the meaning of intonational contours. We propse that S chooses an intonational countour to convey relationships between ( the propositional content of) the current utterance and previous and subsequent utterances. -- and between (the propositional content of) the current utterance and beliefs H believes to be mutually held. These relationships are conveyed compositionally via selection of pitch accent, phrase accent, and boundary tone. Pitch accdents convey information about the status of discourse referents, modifiers, predicates, and relationships specified by accented lexical items. Phrase accents convey information about the relatedness of intermediate phrases --in particular, whether (the propositional content of) one intermediate phrase is to form part of a larger interpretive unit with another. Boundary tones convey information about the directionaliy of interpretation for the current intonational phrase -- whether it is "forward-looking" or not. So, not only do different features of an intonational phrase convey differnt aspects of its meaning, but the meaning conveyeytd by each feature has scope over a different phonological domain. Together, pitch accents, phrase accents, and boundary tones convey how H should interpret the current utterance structurally -- with respect to previous and subsequent utterances -- and with respect to what H believes to be mutually believed in the discourse.},
	author = {Pierrehumbert, Janet and Hirschberg, Julia},
	booktitle = {Intentions in communication},
	file = {:C$\backslash$:/Users/Optiplex 990/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Pierrehumbert et al. - Unknown - The Meaning of Intonational Contours in the Interpretation of Discourse.pdf:pdf},
	number = {14},
	pages = {271--311},
	title = {{The meaning of intonational contours in the interpretation of discourse BT - Intentions in communication}},
	url = {http://www.phon.ox.ac.uk/jpierrehumbert/publications/PierrehumbertHirschberg1990.pdf papers3://publication/uuid/6D3FD89C-CD2E-4AF6-87E7-942819F5B626},
	year = {1990}
}
@article{Huang2006,
	abstract = {Recently, there has been an increasing interest in utilizing a wide variety of knowledge sources in order to label speech with event tags, such as sentence boundaries and dialogue acts. In addition to the words spoken, the prosodic content of the speech can be quite valuable for accurate event tagging. Shriberg and Stolcke (2004) have pioneered the “direct modeling” approach to exploit prosodic information in a variety of spoken language processing tasks such as sentence segmentation and tagging (Liu et al., 2004; Liu et al., 2005a), disfluency detection (Liu et al., 2005b), dialog act segmentation and tagging (Ang et al., 2005), and speaker recognition (Sonmez et al., 1998). An advantage of this approach is that no hand segmentation or intermediate labeling of the prosody is required (although if it were available it could be used). Instead the prosodic features are extracted directly from the speech signal given its time alignment to a human generated transcription or to automatic speech recognition (ASR) output. A prosody model can then be trained using these features and combined with a language model to build an event detection system.},
	author = {Huang, Zhongqiang and Chen, Lei and Harper, Mary},
	doi = {10.1177/1039856214553314},
	file = {:C$\backslash$:/Users/Optiplex 990/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Huang, Chen, Harper - Unknown - An Open Source Prosodic Feature Extraction Tool.pdf:pdf},
	isbn = {1440-1665 (Electronic)$\backslash$r1039-8562 (Linking)},
	issn = {0022-3697},
	journal = {Proc of the Language Resources and {\ldots}},
	keywords = {methodology,prosody},
	pages = {2116--2121},
	pmid = {25313289},
	title = {{An open source prosodic feature extraction tool}},
	url = {https://pdfs.semanticscholar.org/73dc/883657f34719de33c5b32a5717cdd07a429b.pdf http://my.fit.edu/{~}vkepuska/ece5525/Projects/Fall2007/Koneru Dileep/Praat-Prosody/praat prosody/lrec06{\_}prosody.pdf{\%}5Cnpapers3://publication/uuid/EC50EC03-CD20-4C91-9C34-AB1FCEE},
	year = {2006}
}
@article{Pierrehumbert1980,
	author = {Pierrehumbert, Janet Breckenridge},
	file = {:C$\backslash$:/Users/Optiplex 990/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Pierrehumbert - 1980 - THEPHCNOLOGY AND PHONETICS OF ENGLISH INTONATION.pdf:pdf},
	journal = {Linguistics and Philosophy},
	number = {1975},
	title = {{Janet breckenridge pierrehumbert}},
	year = {1980}
}
@phdthesis{Liu2016,
	author = {Liu, Jingzhi},
	file = {:C$\backslash$:/Users/Optiplex 990/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Supervised, Villa-Uriol - 2016 - An Application for Emotion Recognition in Speech.pdf:pdf},
	number = {May},
	title = {{An Application for Emotion Recognition in Speech}},
	url = {https://www.dcs.shef.ac.uk/intranet/archive/campus/2015{\_}2016/projects/msc/acp15jl.pdf},
	year = {2016}
}
@article{Brenier2005,
	abstract = {In this study, we describe an automatic detector for prosodically salient or emphasized words in speech. Knowledge of whether a word is emphatic or not could improve Text-to-Speech synthesis as well as spoken language summarization. Previous work on emphasis detection has focused on the automatic recognition of pitch accents. Our model extends earlier research by automatically identifying emphatic pitch accents, a subset of pitch accents that mark special discourse functions with extreme degrees of salience. The overall best performance achieved by our system was 87.8{\%} correct, 8.0{\%} above baseline performance. The results of a feature selection algorithm show that the top-performing features in our models are primarily acoustic measures. Our work identifies important cues for emphasis in speech and shows that it is possible for an automated system to distinguish between two levels of perceived prominence in pitch accents with a high degree of accuracy.},
	author = {Brenier, Jm and Cer, Dm and Jurafsky, Daniel},
	file = {:C$\backslash$:/Users/Optiplex 990/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Brenier, Cer, Jurafsky - Unknown - The Detection of Emphatic Words Using Acoustic and Lexical Features.pdf:pdf},
	journal = {Interspeech},
	pages = {3297--3300},
	title = {{The Detection of Emphatic Words Using Acoustic and Lexical Features}},
	url = {https://www.isca-speech.org/archive/archive{\_}papers/interspeech{\_}2005/i05{\_}3297.pdf http://t3-1.yum2.net/index/www-nlp.Stanford.EDU/pubs/p1034.pdf},
	year = {2005}
}
@article{Mary2008,
	abstract = {In this paper, we propose a new approach for extracting and representing prosodic features directly from the speech signal. We hypothesize that prosody is linked to linguistic units such as syllables, and it is manifested in terms of changes in measurable parameters such as fundamental frequency (F0), duration and energy. In this work, syllable-like unit is chosen as the basic unit for representing the prosodic characteristics. Approximate segmentation of continuous speech into syllable-like units is obtained by locating the vowel onset points (VOP) automatically. The knowledge of the VOPs serve as reference for extracting prosodic features from the speech signal. Quantitative parameters are used to represent F0 and energy contour in each region between two consecutive VOPs. Prosodic features extracted using this approach may be useful in applications such as recognition of language or speaker, where explicit phoneme/syllable boundaries are not easily available. The effectiveness of the derived prosodic features for language and speaker recognition is evaluated in the case of NIST language recognition evaluation 2003 and the extended data task of NIST speaker recognition evaluation 2003, respectively. {\textcopyright} 2008 Elsevier B.V. All rights reserved.},
	author = {Mary, Leena and Yegnanarayana, B},
	doi = {10.1016/j.specom.2008.04.010},
	file = {:C$\backslash$:/Users/Optiplex 990/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Mary, Yegnanarayana - Unknown - Extraction and representation of prosodic features for language and speaker recognition.pdf:pdf},
	issn = {01676393},
	journal = {Speech Communication},
	keywords = {Autoassociative neural network,Intonation,Language recognition,Multilayer feedforward neural network,Prosody,Rhythm,Speaker recognition,Stress,Vowel onset point},
	number = {10},
	pages = {782--796},
	title = {{Extraction and representation of prosodic features for language and speaker recognition}},
	url = {www.elsevier.com/locate/specom},
	volume = {50},
	year = {2008}
}
@article{Keating2006,
	abstract = {Contrasting phonation types in languages can differ along several acoustic dimensions},
	author = {Keating, Patricia A and Esposito, Christina Marie},
	file = {:C$\backslash$:/Users/Optiplex 990/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Keating, Esposito - Unknown - Linguistic Voice Quality.pdf:pdf},
	journal = {Proceedings of the Eleventh Australasian International Conference on Speech Science and Technology},
	number = {105},
	pages = {85--91},
	title = {{Linguistic Voice Quality *}},
	url = {https://pdfs.semanticscholar.org/93b0/319eba784f9d2832cf1c4dd042637c0c62a8.pdf?{\_}ga=2.227727582.277507270.1558024884-1832815252.1558024884},
	year = {2006}
}
@inproceedings{Bailly2005,
	abstract = {This paper introduces a new model-constrained and data-driven system to generate prosody from metalinguistic information. This system considers the prosodic continuum as the superposition of multiple elementary overlapping multiparametric contours. These contours encode specific metalinguistic functions associated with various discourse units. We describe the phonological model underlying the system and the specific implementation made of that model by the trainable prosodic model described here. The way prosody is analyzed, decomposed and modelled is illustrated by experimental work. In particular, we describe the original training procedure that enables the system to identify the elementary contours and to separate out their contributions to the prosodic contours of the training data. {\textcopyright} 2005 Elsevier B.V. All rights reserved.},
	author = {Bailly, G{\'{e}}rard and Holm, Bleicke},
	booktitle = {Speech Communication},
	doi = {10.1016/j.specom.2005.04.008},
	file = {:C$\backslash$:/Users/Optiplex 990/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Bailly, Holm - 2005 - SFC A trainable prosodic model.pdf:pdf},
	issn = {01676393},
	keywords = {Automatic generation of prosody,Intonation,Prosodic modelling},
	number = {3-4},
	pages = {348--364},
	title = {{SFC: A trainable prosodic model}},
	url = {www.elsevier.com/locate/specom},
	volume = {46},
	year = {2005}
}
@article{Nakatani1997,
	abstract = {Intonational prominence, or accent, is a fundamental prosodic feature that is said to contribute to discourse meaning. This thesis outlines a new, computational theory of the discourse interpretation of prominence, from a FUNCTIONAL PROSODY perspective. Functional prosody makes the following two important assumptions: first, there is an aspect of prominence interpretation that centrally concerns discourse processes, namely the discourse focusing nature of prominence; and second, the role of prominence in language processing in general, and discourse processing in particular, is not essentially separate from the processing of other grammatical, nonprosodic information. This thesis develops a computational theory of prominence interpretation by explaining how prominence serves as an inference cue in discourse processing. Prominence signals changes in the attentional status of entities in a discourse model, while nonprominence signals that the realized entities are already in discourse focus. Evidence for the new theory is provided by distributional analysis of a spontaneous narrative monologue. New discourse processing algorithms that integrate form of expression, grammatical function and intonational prominence information for reference resolution and attentional state modeling show how the principles of the theory may be applied in SPEECH UNDERSTANDING systems. Finally, aspects of the new theory are explored in accent prediction experiments on a corpus of spontaneous and read direction-giving monologues. Machine learning is used to investigate the extent to which the analyzed higher-level linguistic features associated with prominence may combine with lower-level features that are known to influence accent assignment. Original constituent-based accent prediction experiments attempt to bootstrap off of established knowledge about citation-form accenting, and begin to develop an understanding of how the examined features of discourse context may be integrated into accent assignment systems for text-to-speech synthesis.},
	author = {Nakatani, Christine Hisayo},
	file = {:C$\backslash$:/Users/Optiplex 990/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Nakatani - 1997 - The Computational Processing of Intonational Prominence A Functional Prosody Perspective.pdf:pdf},
	issn = {04194217},
	journal = {Dissertation Abstracts International, B: Sciences and Engineering},
	number = {5},
	title = {{The Computational Processing of Intonational Prominence: A Functional Prosody Perspective}},
	url = {https://dash.harvard.edu/bitstream/handle/1/25619466/tr-15-97.pdf?sequence=1{\&}isAllowed=y},
	volume = {58},
	year = {1997}
}
@article{Hirschberg2002,
	abstract = {Interest in the contribution prosodic information makes to human communication has led to increasing expectations that such information could be of use in text-to-speech and speech understanding systems, and in application of these technologies to spoken dialogue systems. To date, research results far exceed their technology applications. This paper suggests some areas in which progress has been made, and some in which more might be made, with particular emphasis upon text-to-speech synthesis and spoken dialogue systems. {\textcopyright} 2002 Elsevier Science B.V. All rights reserved.},
	author = {Hirschberg, Julia},
	doi = {10.1016/S0167-6393(01)00024-3},
	file = {:C$\backslash$:/Users/Optiplex 990/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Hirschberg - 2002 - Communication and prosody Functional aspects of prosody.pdf:pdf},
	issn = {01676393},
	journal = {Speech Communication},
	keywords = {Intonational meaning,Prosody,Spoken dialogue systems},
	number = {1-2},
	pages = {31--43},
	title = {{Communication and prosody: Functional aspects of prosody}},
	url = {http://ling.ohio-state.edu/tobi.},
	volume = {36},
	year = {2002}
}
@article{Tran2017,
	abstract = {In conversational speech, the acoustic signal provides cues that help listeners disambiguate difficult parses. For automatically parsing spoken utterances, we introduce a model that integrates transcribed text and acoustic-prosodic features using a convolutional neural network over energy and pitch trajectories coupled with an attention-based recurrent neural network that accepts text and prosodic features. We find that different types of acoustic-prosodic features are individually helpful, and together give statistically significant improvements in parse and disfluency detection F1 scores over a strong text-only baseline. For this study with known sentence boundaries, error analyses show that the main benefit of acoustic-prosodic features is in sentences with disfluencies, attachment decisions are most improved, and transcription errors obscure gains from prosody.},
	archivePrefix = {arXiv},
	arxivId = {1704.07287},
	author = {Tran, Trang and Toshniwal, Shubham and Bansal, Mohit and Gimpel, Kevin and Livescu, Karen and Ostendorf, Mari},
	eprint = {1704.07287},
	file = {:C$\backslash$:/Users/Optiplex 990/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Tran et al. - 2017 - Parsing Speech A Neural Approach to Integrating Lexical and Acoustic-Prosodic Information.pdf:pdf},
	title = {{Parsing Speech: A Neural Approach to Integrating Lexical and Acoustic-Prosodic Information}},
	url = {https://arxiv.org/pdf/1704.07287.pdf http://arxiv.org/abs/1704.07287},
	year = {2017}
}
@article{Calhoun2010,
	abstract = {A key function of prosodic prominence is to mark the most informative words in an utterance. However, informativeness has been conceptualised as, e.g., focus, given/new status or predictability; it is not clear how these are related. Furthermore, prominence is constrained by metrical prosodic structure. We present a new framework for prominence production: informativeness and prosodic factors are constraints on the probabilistic alignment of words with metrical structure. Informativeness operates on two levels, focus and lexical ‘‘accentability'' (predictability, part-of-speech). Foci align with nuclear accents, however, this is affected by prosodic and ‘‘accentability'' constraints. Accent prediction models (nuclear, non-nuclear, or unaccented) are presented for the Switchboard corpus. Consistent with our predictions, nuclear accents are more likely later in a phrase, and on focused words. The likelihood of nuclear and non-nuclear accents is affected by prosodic constraints (e.g., rhythm) and ‘‘accentability''. The implications for the role of prosody in language production are discussed.},
	author = {Calhoun, Sasha},
	doi = {10.1080/01690965.2010.491682},
	file = {:C$\backslash$:/Users/Optiplex 990/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Calhoun - 2010 - How does informativeness affect prosodic prominence.pdf:pdf},
	issn = {01690965},
	journal = {Language and Cognitive Processes},
	keywords = {Discourse processing,Information structure,Prosody},
	number = {7},
	pages = {1099--1140},
	title = {{How does informativeness affect prosodic prominence?}},
	url = {https://www.tandfonline.com/action/journalInformation?journalCode=plcp21},
	volume = {25},
	year = {2010}
}
@article{Kafle2019,
	abstract = {Prosodic cues in conversational speech aid listeners in discerning a message. We investigate whether acoustic cues in spoken dialogue can be used to identify the importance of individual words to the meaning of a conversation turn. Individuals who are Deaf and Hard of Hearing often rely on real-time captions in live meetings. Word error rate, a traditional metric for evaluating automatic speech recognition, fails to capture that some words are more important for a system to transcribe correctly than others. We present and evaluate neural architectures that use acoustic features for 3-class word importance prediction. Our model performs competitively against state-of-the-art text-based word-importance prediction models, and it demonstrates particular benefits when operating on imperfect ASR output.},
	archivePrefix = {arXiv},
	arxivId = {1903.12238},
	author = {Kafle, Sushant and Alm, Cecilia O and Huenerfauth, Matt},
	eprint = {1903.12238},
	file = {:C$\backslash$:/Users/Optiplex 990/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Kafle, Alm, Huenerfauth - 2019 - Modeling Acoustic-Prosodic Cues for Word Importance Prediction in Spoken Dialogues.pdf:pdf},
	title = {{Modeling Acoustic-Prosodic Cues for Word Importance Prediction in Spoken Dialogues}},
	url = {https://arxiv.org/pdf/1903.12238.pdf http://arxiv.org/abs/1903.12238},
	year = {2019}
}
@book{Jurafsky2008,
	abstract = {applicability for this approach.},
	archivePrefix = {arXiv},
	arxivId = {arXiv:1011.1669v3},
	author = {Jurafsky, Daniel and Martin, James H.},
	booktitle = {Speech and Language Processing An Introduction to Natural Language Processing Computational Linguistics and Speech Recognition},
	doi = {10.1017/CBO9781107415324.004},
	eprint = {arXiv:1011.1669v3},
	file = {:C$\backslash$:/Users/Optiplex 990/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Jurafsky, Martin - 2008 - 2nd{\_}ed{\_}draft Speech and Language Processing.pdf:pdf},
	isbn = {9788578110796},
	issn = {1098-6596},
	pages = {0--934},
	pmid = {25246403},
	publisher = {Prentice Hall},
	title = {{2nd{\_}ed{\_}draft: Speech and Language Processing}},
	url = {http://www.mitpressjournals.org/doi/pdf/10.1162/089120100750105975},
	volume = {21},
	year = {2008}
}
@incollection{Hirschberg2017,
	abstract = {The aim of this chapter is to give the reader an idea of the various dimensions along which the debates on the relationship between pragmatics and prosody take place, then go on to suggest ways in which studies in this area might be advanced. It is based around three questions. For ease of presentation, the three questions are dealt within three separate sections (so question (1) is dealt with in section 2, question (2) in section 3 and question (3) in section 4). The questions are, however, inter-related, and consequently the answers to them are inter-linked: (1) How should the different types of prosody be characterised? (2) What is the relationship between prosody and intentional communication? (3) What kind of meaning does prosody encode (if anything)?},
	author = {Hirschberg, Julia},
	booktitle = {The Cambridge Handbook of Pragmatics},
	doi = {10.1017/cbo9781139022453.031},
	file = {:C$\backslash$:/Users/Optiplex 990/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Hirschberg - 2017 - Pragmatics and prosody.pdf:pdf},
	isbn = {9780199697960},
	pages = {532--549},
	title = {{Pragmatics and prosody}},
	url = {www.ling.ohio-state.edu/},
	year = {2017}
}

Schuller, B.W.: Speech emotion recognition: Two decades in a nutshell, benchmarks, and ongoing trends. Communications of the ACM 61(5), 90–99 (2018)
Bagshaw, P.C., Automatic prosodic analysis for computer-aided pronunciation teaching. PhD thesis, University of Edimburgh, 1994.
Beckman, M.E., Stress and non-stress accent. Foris Publications, Dordrecht, Holland , 1986.

Streefkerk, B M. et al., “Acoustical features as predictors for prominence in read aloud Dutch sentences used in ANN's.”, In Proc. Eurospeech '99, Budapest, pp. 551- 554, 1999
Sluijter, A. and van Heuven, V., “Acoustic correlates of linguistic stress and accent in Dutch and American English.”, In Proc. ICSLP96, Philadelphia, pp. 630-633, 1996
